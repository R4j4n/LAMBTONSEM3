{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/r1j1n/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/r1j1n/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/r1j1n/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "\n",
    "# Download NLTK resources (run this once per Colab session)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded text corpus\n",
    "corpus = \"\"\"\n",
    "Artificial intelligence (AI) is a wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence.\n",
    "AI is becoming more and more integrated with daily life, from virtual assistants on phones to complex algorithms used to make business decisions.\n",
    "Machine Learning (ML) is a subfield of AI that focuses on algorithms that can learn from data.\n",
    "Deep learning (DL) is a more specialized subfield of ML using neural networks with many layers, allowing for more complex pattern recognition.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, lowercase, and remove punctuation from text\n",
    "def preprocess_text(text):\n",
    "  text = text.lower()\n",
    "  text = ''.join([char for char in text if char not in string.punctuation]) # removing punctuation\n",
    "  tokens = word_tokenize(text) # tokenizing\n",
    "  return tokens\n",
    "\n",
    "# Simple function to process a question and find the best matching sentence\n",
    "def simple_qa(question, corpus):\n",
    "  # Preprocess both text corpus and the question\n",
    "  corpus_tokens = [preprocess_text(sentence) for sentence in corpus.split('\\n') if sentence]\n",
    "  question_tokens = preprocess_text(question)\n",
    "\n",
    "  # Vectorize text corpus and question using TF-IDF\n",
    "  vectorizer = TfidfVectorizer(tokenizer=lambda x:x, preprocessor=lambda x:x) # Using tokenizer to skip text processing and vectorizing pre-processed tokens\n",
    "  vectorizer.fit(corpus_tokens)\n",
    "  corpus_vectors = vectorizer.transform(corpus_tokens)\n",
    "  question_vector = vectorizer.transform([question_tokens])\n",
    "\n",
    "  # Finding the sentence with the highest cosine similarity\n",
    "  similarity_scores = cosine_similarity(question_vector, corpus_vectors).flatten()\n",
    "  best_match_index = np.argmax(similarity_scores)\n",
    "\n",
    "  # Return the best matching sentence\n",
    "  return corpus.split('\\n')[best_match_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Corpus used for this example is : \n",
      " \n",
      "Artificial intelligence (AI) is a wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence.\n",
      "AI is becoming more and more integrated with daily life, from virtual assistants on phones to complex algorithms used to make business decisions.\n",
      "Machine Learning (ML) is a subfield of AI that focuses on algorithms that can learn from data.\n",
      "Deep learning (DL) is a more specialized subfield of ML using neural networks with many layers, allowing for more complex pattern recognition.\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Question: What is AI?\n",
      "Answer: AI is becoming more and more integrated with daily life, from virtual assistants on phones to complex algorithms used to make business decisions.\n",
      "\n",
      "Question: Tell me about machine learning.\n",
      "Answer: AI is becoming more and more integrated with daily life, from virtual assistants on phones to complex algorithms used to make business decisions.\n",
      "\n",
      "Question: what does Deep Learning do?\n",
      "Answer: Machine Learning (ML) is a subfield of AI that focuses on algorithms that can learn from data.\n",
      "\n",
      "Question: What are the applications of AI?\n",
      "Answer: \n",
      "\n",
      "Question: How many subfields of AI are in this text?\n",
      "Answer: Machine Learning (ML) is a subfield of AI that focuses on algorithms that can learn from data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r1j1n/miniconda3/envs/audio/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample questions\n",
    "questions = [\n",
    "    \"What is AI?\",\n",
    "    \"Tell me about machine learning.\",\n",
    "    \"what does Deep Learning do?\",\n",
    "    \"What are the applications of AI?\",\n",
    "    \"How many subfields of AI are in this text?\" #testing questions beyond the text\n",
    "]\n",
    "\n",
    "# Process questions and print results\n",
    "print(\"The Corpus used for this example is : \\n\", corpus)\n",
    "print(\"\\n-------------------------------------\\n\")\n",
    "for question in questions:\n",
    "    answer = simple_qa(question, corpus)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
